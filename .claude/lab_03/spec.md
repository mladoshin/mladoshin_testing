# Лабораторная работа №3: Benchmark производительности
# Спецификация проекта "Школа онлайн курсов"

## 1. Общая информация

**Название проекта:** Performance Benchmark для "Школа онлайн курсов"
**Тип проекта:** Лабораторная работа №3 по дисциплине "Тестирование и отладка"
**Автор:** Ладошин Максим
**Версия:** 1.0.0
**Дата создания:** 2025-11-12

## 2. Цель лабораторной работы

Разработать комплексный набор бенчмарков для оценки производительности NestJS backend приложения "Школа онлайн курсов" с использованием статистического анализа, мониторинга ресурсов и визуализации результатов.

## 3. Объект исследования

**Основной объект:** NestJS Backend API (Node.js + TypeScript + PostgreSQL + Redis)

**Технологический стек объекта:**
- Runtime: Node.js 20.x
- Framework: NestJS 11.x
- Database: PostgreSQL 16.x
- Cache: Redis 7.x
- ORM: TypeORM 0.3.x

## 4. Сценарии тестирования

### 4.1 Сценарий 1: Аутентификация и авторизация
**Тип нагрузки:** CPU-bound + IO-bound (хеширование + БД запросы)

**Тестируемые endpoints:**
- `POST /api/auth/register` — регистрация нового пользователя
- `POST /api/auth/login` — авторизация пользователя
- `POST /api/auth/refresh` — обновление токена

**Измеряемые метрики:**
- Время обработки запроса регистрации (включая bcrypt хеширование)
- Время обработки запроса авторизации
- Время генерации JWT токенов
- Количество одновременных успешных авторизаций
- Латентность при массовой регистрации пользователей

**Профиль нагрузки:**
- Warm-up: 50 запросов
- Baseline: 100 VU (Virtual Users), 5 минут
- Stress: постепенное увеличение до 500 VU
- Spike: резкий скачок до 1000 VU на 1 минуту
- Recovery: возврат к 100 VU

### 4.2 Сценарий 2: Работа с курсами
**Тип нагрузки:** IO-bound (БД запросы + кеширование)

**Тестируемые endpoints:**
- `GET /api/courses` — список курсов с пагинацией
- `GET /api/courses/:id` — детали курса
- `POST /api/courses` — создание курса (администратор)
- `PUT /api/courses/:id` — обновление курса (администратор)

**Измеряемые метрики:**
- Время ответа GET запросов (холодный кеш vs горячий кеш)
- Throughput (запросов в секунду)
- Время обработки создания курса с уроками
- Эффективность Redis кеширования
- Латентность при конкурентных запросах на чтение

**Профиль нагрузки:**
- Чтение: 80% запросов (GET)
- Запись: 20% запросов (POST/PUT)
- Constant load: 200 VU, 10 минут
- Ramping: от 50 до 500 VU за 5 минут

### 4.3 Сценарий 3: Платежные транзакции
**Тип нагрузки:** IO-bound + транзакционная нагрузка (ACID)

**Тестируемые endpoints:**
- `POST /api/payments` — создание платежа
- `GET /api/payments` — список платежей (администратор)
- `POST /api/course-enrollments` — регистрация на курс после оплаты

**Измеряемые метрики:**
- Время обработки транзакции оплаты
- Гарантии ACID (проверка консистентности)
- Количество успешных платежей при конкурентных запросах
- Латентность цепочки "оплата → регистрация на курс"
- Rollback время при ошибках

**Профиль нагрузки:**
- Sequential: 100 платежей последовательно
- Concurrent: 50 одновременных платежей
- Peak load: 200 VU на 3 минуты

### 4.4 Сценарий 4: Комплексный пользовательский сценарий
**Тип нагрузки:** Mixed (все типы операций)

**Последовательность действий:**
1. Регистрация пользователя
2. Авторизация
3. Просмотр списка курсов
4. Просмотр деталей 3 курсов
5. Оплата курса
6. Регистрация на курс
7. Просмотр уроков курса

**Измеряемые метрики:**
- Общее время выполнения сценария
- Latency каждого шага
- Success rate всего flow
- User experience метрики (p95, p99 latency)

**Профиль нагрузки:**
- 100 пользователей одновременно проходят весь сценарий
- Запуск 100 раз для статистической значимости

## 5. Точки деградации производительности

### 5.1 Поиск точки деградации
**Метод:** Постепенное увеличение нагрузки (Ramp-up test)

**Параметры:**
- Начальная нагрузка: 10 VU
- Шаг увеличения: +50 VU каждые 2 минуты
- Максимум: 2000 VU
- Критерий деградации: p95 latency > 2000ms или error rate > 1%

**Отслеживаемые признаки деградации:**
- Увеличение времени ответа более чем в 2 раза
- Рост потребления памяти > 90% доступной
- CPU throttling > 80%
- Появление connection timeout ошибок
- Увеличение очереди в БД

### 5.2 Работа на максимальной нагрузке
**Метод:** Sustained load test

**Параметры:**
- Нагрузка: 80% от точки деградации
- Длительность: 30 минут
- Проверка стабильности системы под длительной нагрузкой

**Отслеживаемые метрики:**
- Стабильность latency во времени
- Memory leaks (постоянный рост RAM)
- CPU throttling patterns
- БД connection pool saturation

### 5.3 Восстановление после перегруза
**Метод:** Recovery test

**Параметры:**
1. Перегруз: 150% от точки деградации, 5 минут
2. Снижение до baseline: 100 VU
3. Мониторинг восстановления: 10 минут

**Отслеживаемые метрики:**
- Время восстановления нормальной latency
- Количество failed requests после перегруза
- Скорость освобождения ресурсов (RAM, CPU)
- Восстановление БД connection pool

## 6. Инструменты и технологии

### 6.1 Генерация нагрузки
**Основной инструмент:** k6 (https://k6.io/)

**Обоснование выбора:**
- Современный, производительный load testing tool
- Поддержка JavaScript/TypeScript для сценариев
- Встроенные метрики и перцентили
- Экспорт данных в различные форматы (JSON, CSV, InfluxDB)
- Поддержка различных профилей нагрузки

**Альтернатива:** Apache JMeter (для сравнения результатов)

### 6.2 Мониторинг ресурсов
**Основные инструменты:**
- **Prometheus** — сбор метрик (https://prometheus.io/)
- **Grafana** — визуализация метрик (https://grafana.com/)
- **cAdvisor** — мониторинг Docker контейнеров
- **PostgreSQL Exporter** — метрики базы данных
- **Redis Exporter** — метрики Redis

**Собираемые метрики:**
- **CPU:** utilization (%), throttling events
- **RAM:** used/total, RSS, heap size
- **Network:** bytes in/out, connections count
- **Disk I/O:** read/write bytes, IOPS
- **PostgreSQL:** active connections, query duration, locks
- **Redis:** hit rate, memory usage, commands/sec
- **Node.js:** event loop delay, GC pauses, heap usage

### 6.3 Контейнеризация
**Технология:** Docker + Docker Compose

**Компоненты:**
- Backend (NestJS app) — фиксированные ресурсы: 2 CPU, 2GB RAM
- PostgreSQL — фиксированные ресурсы: 2 CPU, 2GB RAM
- Redis — фиксированные ресурсы: 1 CPU, 512MB RAM
- Prometheus — 1 CPU, 512MB RAM
- Grafana — 1 CPU, 512MB RAM

**Изоляция:**
- Каждый компонент в отдельном контейнере
- Docker network для изоляции трафика
- Volume persistence для данных БД

### 6.4 Обработка данных
**Инструменты:**
- **Python 3.11+** — обработка и анализ данных
- **Pandas** — манипуляция табличными данными
- **Matplotlib / Plotly** — построение графиков
- **NumPy** — статистические расчеты
- **Jupyter Notebook** — интерактивный анализ

## 7. Измеряемые метрики

### 7.1 Метрики времени выполнения
**Основные перцентили:**
- p50 (медиана)
- p75
- p90
- p95
- p99

**Визуализация:**
- График latency во времени (timeline)
- Гистограмма распределения latency
- Percentile distribution chart
- Box plot для каждого endpoint

### 7.2 Метрики throughput
- Requests per second (RPS)
- Успешные запросы / общее количество
- Error rate (%)
- Timeout rate (%)

### 7.3 Метрики ресурсов
**Формат данных:**
```json
{
  "component": "backend",
  "cpu": {
    "min": 5.2,
    "max": 78.5,
    "median": 45.3,
    "mean": 42.1,
    "unit": "%"
  },
  "memory": {
    "min": 512,
    "max": 1843,
    "median": 1205,
    "mean": 1150,
    "unit": "MB"
  },
  "network": {
    "bytes_in": 1234567890,
    "bytes_out": 987654321,
    "unit": "bytes"
  }
}
```

**Визуализация:**
- Time-series графики CPU/RAM/Network
- Heatmap корреляции метрик
- Resource utilization stacked chart

## 8. Архитектура benchmark системы

### 8.1 Структура проекта
```
apps/backend/benchmarks/
├── k6/                          # k6 тестовые сценарии
│   ├── scenarios/
│   │   ├── auth.js              # Сценарий аутентификации
│   │   ├── courses.js           # Сценарий работы с курсами
│   │   ├── payments.js          # Сценарий платежей
│   │   └── full-flow.js         # Комплексный сценарий
│   ├── config/
│   │   ├── baseline.json        # Конфигурация baseline
│   │   ├── stress.json          # Конфигурация stress
│   │   └── spike.json           # Конфигурация spike
│   └── utils/
│       ├── setup.js             # Подготовка тестовых данных
│       └── helpers.js           # Вспомогательные функции
├── docker/
│   ├── docker-compose.bench.yml # Compose для benchmark
│   ├── Dockerfile.bench         # Dockerfile для backend
│   └── prometheus.yml           # Конфигурация Prometheus
├── scripts/
│   ├── run-benchmark.sh         # Главный скрипт запуска
│   ├── run-iteration.sh         # Запуск одной итерации
│   ├── collect-metrics.sh       # Сбор метрик с Prometheus
│   └── cleanup.sh               # Очистка после тестов
├── analysis/
│   ├── process_results.py       # Обработка результатов k6
│   ├── analyze_metrics.py       # Анализ метрик Prometheus
│   ├── generate_report.py       # Генерация финального отчета
│   └── visualize.py             # Построение графиков
├── results/                     # Результаты тестов
│   ├── iteration_001/
│   │   ├── k6_results.json
│   │   ├── metrics.json
│   │   └── logs/
│   ├── iteration_002/
│   └── ...
└── reports/                     # Финальные отчеты
    ├── summary.json             # Сводная статистика
    ├── graphs/                  # Графики
    └── report.html              # HTML отчет
```

### 8.2 Workflow выполнения benchmark

**Шаг 1: Подготовка окружения**
```bash
./scripts/run-benchmark.sh --iterations 100 --scenario all
```

**Шаг 2: Цикл итераций (100 раз)**
Для каждой итерации:
1. Поднять Docker окружение (backend + PostgreSQL + Redis + Prometheus)
2. Дождаться healthy status всех контейнеров
3. Выполнить warm-up (50 запросов)
4. Запустить k6 сценарий с выбранным профилем нагрузки
5. Собрать метрики из Prometheus
6. Экспортировать результаты k6 в JSON
7. Остановить и удалить все контейнеры
8. Сохранить результаты итерации в `results/iteration_NNN/`

**Шаг 3: Агрегация результатов**
После 100 итераций:
1. Загрузить все JSON результаты
2. Вычислить статистики по всем метрикам
3. Построить графики распределений
4. Сгенерировать сводный отчет

**Шаг 4: Генерация отчета**
```bash
python analysis/generate_report.py --input results/ --output reports/
```

## 9. Требования к отчетам

### 9.1 Структура отчета
**Формат:** HTML + JSON + PDF

**Разделы:**
1. **Executive Summary**
   - Основные выводы
   - Найденные точки деградации
   - Рекомендации по оптимизации

2. **Тестовое окружение**
   - Спецификация железа
   - Конфигурация контейнеров
   - Версии софта

3. **Результаты по сценариям**
   Для каждого сценария:
   - График latency timeline
   - Гистограмма распределения
   - Percentile distribution
   - Таблица с перцентилями (p50, p75, p90, p95, p99)
   - Throughput metrics

4. **Утилизация ресурсов**
   - Таблица min/max/median/mean для каждого компонента
   - Time-series графики CPU/RAM/Network
   - Correlation heatmap

5. **Точки деградации**
   - График поиска точки деградации
   - Анализ поведения под максимальной нагрузкой
   - График восстановления после перегруза

6. **Сравнительный анализ** (если есть альтернативный объект)
   - Side-by-side comparison
   - Относительные метрики

### 9.2 Графики (обязательные)
1. **Latency timeline** (для каждого сценария)
   - X: время, Y: latency (ms)
   - Линии для p50, p95, p99

2. **Latency histogram** (для каждого сценария)
   - X: latency buckets, Y: count

3. **Percentile distribution** (для каждого сценария)
   - X: percentile (0-100), Y: latency (ms)

4. **Resource utilization timeline**
   - CPU: X: время, Y: %
   - RAM: X: время, Y: MB
   - Network: X: время, Y: MB/s

5. **Throughput timeline**
   - X: время, Y: requests/sec

6. **Degradation point search**
   - X: VU count, Y: p95 latency

7. **Recovery timeline**
   - X: время, Y: latency
   - Пометки: перегруз → восстановление

### 9.3 Экспорт данных
**Форматы:**
- JSON: полные результаты для программной обработки
- CSV: табличные данные для Excel/Pandas
- HTML: интерактивный отчет с графиками
- PDF: статический отчет для печати

## 10. Критерии успешности

### 10.1 Технические критерии
- Выполнено минимум 100 итераций каждого сценария
- Собраны метрики ресурсов для всех компонентов
- Построены все обязательные графики
- Найдена точка деградации производительности
- Проверено восстановление после перегруза

### 10.2 Качественные критерии
- Результаты воспроизводимы (стандартное отклонение < 15%)
- Четко определена максимальная пропускная способность
- Выявлены узкие места (bottlenecks)
- Даны рекомендации по оптимизации

### 10.3 Документация
- Отчет содержит все требуемые разделы
- Графики читаемы и информативны
- Выводы обоснованы данными
- Есть сравнение с baseline (если применимо)

## 11. Ограничения ресурсов

### 11.1 Docker контейнеры
**Backend container:**
- CPU limit: 2 cores
- Memory limit: 2GB
- No swap

**PostgreSQL container:**
- CPU limit: 2 cores
- Memory limit: 2GB
- Shared buffers: 512MB

**Redis container:**
- CPU limit: 1 core
- Memory limit: 512MB
- Max memory policy: allkeys-lru

**Prometheus container:**
- CPU limit: 1 core
- Memory limit: 512MB

**Grafana container:**
- CPU limit: 1 core
- Memory limit: 512MB

### 11.2 Хост система (минимальные требования)
- CPU: 8 cores (для изоляции генератора и тестируемой системы)
- RAM: 16 GB
- Disk: SSD, минимум 50 GB свободного места
- Network: 1 Gbps

### 11.3 Изоляция
- Генератор нагрузки (k6) запускается на отдельных CPU ядрах через taskset/cpuset
- Тестируемая система изолирована в Docker с фиксированными ресурсами
- Мониторинг работает в отдельных контейнерах

## 12. Дополнительные исследования

### 12.1 Сравнение с альтернативой (опционально)
**Альтернативный объект:** Express.js + TypeORM (базовая реализация без NestJS)

**Цель:** Оценить overhead NestJS framework

**Метрики сравнения:**
- Latency (p50, p95, p99)
- Throughput (RPS)
- Memory footprint
- Startup time (warm-up period)

### 12.2 Оптимизация на основе результатов
После первого запуска benchmark:
1. Идентифицировать bottlenecks
2. Применить оптимизации (например, увеличить connection pool, добавить индексы БД)
3. Повторно запустить benchmark
4. Сравнить результаты "до" и "после"

## 13. Расписание выполнения

### Этап 1: Подготовка инфраструктуры (3-5 дней)
- Настройка Docker окружения
- Конфигурация Prometheus + Grafana
- Создание базовых k6 сценариев

### Этап 2: Разработка сценариев (5-7 дней)
- Реализация всех 4 сценариев в k6
- Тестирование сценариев
- Валидация профилей нагрузки

### Этап 3: Автоматизация (3-4 дня)
- Скрипты запуска итераций
- Сбор метрик
- Экспорт данных

### Этап 4: Запуск benchmark (2-3 дня)
- Выполнение 100 итераций каждого сценария
- Мониторинг процесса
- Сбор результатов

### Этап 5: Анализ и отчет (3-5 дней)
- Обработка данных
- Построение графиков
- Написание отчета
- Формулировка выводов

**Общая длительность:** 16-24 дня

## 14. Риски и ограничения

### 14.1 Технические риски
- **Нестабильность хост-системы:** Использовать dedicated сервер для тестирования
- **Network latency:** Все компоненты в одной Docker сети, минимизировать внешние запросы
- **Disk I/O bottleneck:** Использовать SSD, мониторить iowait
- **Тепловой throttling:** Контролировать температуру CPU

### 14.2 Ограничения подхода
- Тестирование на одном хосте (не distributed)
- Синтетическая нагрузка (не реальные пользователи)
- Фиксированный dataset (не dynamic data growth)
- Отсутствие network latency симуляции

### 14.3 Mitigations
- Запуск в стабильных условиях (ночью, без фоновых задач)
- Использование Docker resource limits для изоляции
- Мониторинг системных метрик хоста
- Повторные запуски для валидации результатов

## 15. Связь с основным проектом

### 15.1 Интеграция
Benchmark код находится в:
```
apps/backend/benchmarks/
```

Результаты не коммитятся в Git (добавлены в `.gitignore`):
```
apps/backend/benchmarks/results/
apps/backend/benchmarks/reports/
```

### 15.2 CI/CD (опционально)
- Запуск базового benchmark в CI pipeline
- Сравнение с baseline при PR
- Alert при деградации > 10%

## 16. Checklist выполнения

- [ ] Настроено Docker окружение с фиксированными ресурсами
- [ ] Установлены k6, Prometheus, Grafana
- [ ] Реализованы 4 тестовых сценария
- [ ] Созданы скрипты автоматизации
- [ ] Выполнено минимум 100 итераций каждого сценария
- [ ] Собраны метрики ресурсов (CPU, RAM, Network, Disk)
- [ ] Найдена точка деградации производительности
- [ ] Проверена работа под максимальной нагрузкой
- [ ] Проверено восстановление после перегруза
- [ ] Построены все обязательные графики (latency timeline, histogram, percentiles, resources)
- [ ] Вычислены перцентили: p50, p75, p90, p95, p99
- [ ] Экспортированы данные в JSON/CSV
- [ ] Сгенерирован HTML отчет
- [ ] Написаны выводы и рекомендации
- [ ] (Опционально) Выполнено сравнение с альтернативой

## 17. Ссылки и ресурсы

**Документация инструментов:**
- k6: https://k6.io/docs/
- Prometheus: https://prometheus.io/docs/
- Grafana: https://grafana.com/docs/
- cAdvisor: https://github.com/google/cadvisor
- Docker resource limits: https://docs.docker.com/config/containers/resource_constraints/

**Примеры benchmark:**
- TechEmpower: https://github.com/TechEmpower/FrameworkBenchmarks
- The Benchmarker: https://github.com/the-benchmarker/website
- k6 examples: https://github.com/grafana/k6-example-projects

**Статьи:**
- "Load Testing with k6": https://k6.io/docs/test-types/load-testing/
- "Performance Testing Best Practices": https://www.guru99.com/performance-testing.html
- "Node.js Performance Monitoring": https://nodejs.org/en/docs/guides/simple-profiling/

---

**Версия документа:** 1.0.0
**Последнее обновление:** 2025-11-12
**Статус:** Готов к реализации
